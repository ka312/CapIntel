{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68d81e5",
   "metadata": {
    "height": 30
   },
   "source": [
    "## Loading Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd3ad7ef",
   "metadata": {
    "height": 472
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "from rich.text import Text\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List, Optional, Dict, Any\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from tavily import TavilyClient\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "import markdown\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv()\n",
    "\n",
    "# Initialize console and memory\n",
    "console = Console()\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "# Initialize models and clients\n",
    "model = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.2)\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f4ced",
   "metadata": {
    "height": 30
   },
   "source": [
    "##PromptsandStates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a7d0122",
   "metadata": {
    "height": 999
   },
   "outputs": [],
   "source": [
    "INDUSTRY_THESIS_PROMPT = \"\"\"\n",
    "As a venture capital research strategist, develop a comprehensive and data-driven investment thesis for the specified industry. \n",
    "Your response should include:\n",
    "Comprehensive Industry Thesis Development Protocol\n",
    "\n",
    "Objective\n",
    "Develop a rigorous, globally-contextualized investment thesis that provides a nuanced and critically examined perspective on the target industry.\n",
    "\n",
    "Detailed Research Requirements\n",
    "\n",
    "1. Industry Definition and Contextual Analysis\n",
    "- Provide a multi-dimensional definition of the industry\n",
    "- Include:\n",
    "  * Global perspective with regional variations\n",
    "  * Socio-economic context\n",
    "  * Technological ecosystem mapping\n",
    "- Highlight geopolitical and regulatory landscape across different markets\n",
    "\n",
    "2. Market Trends Analysis\n",
    "- Mandate multi-source data validation\n",
    "  * Minimum 3 independent research sources\n",
    "  * Cross-reference global databases (World Bank, IEA, specialized industry reports)\n",
    "- Quantitative trend analysis with:\n",
    "  * Precise numerical data\n",
    "  * Confidence intervals\n",
    "  * Potential deviation scenarios\n",
    "- Include:\n",
    "  * Emerging market trends\n",
    "  * Countertrends and potential disruption points\n",
    "  * Comparative analysis across different geographical contexts\n",
    "\n",
    "3. Technological Disruption Assessment\n",
    "- Comprehensive Technology Evaluation Framework:\n",
    "  * Technical feasibility assessment\n",
    "  * Independent expert review\n",
    "  * Potential failure mode analysis\n",
    "  * Scalability simulation\n",
    "  * Regulatory compliance probability\n",
    "- Technology Readiness Level (TRL) mapping\n",
    "- Potential integration challenges\n",
    "- Comparative technological landscape\n",
    "\n",
    "4. Emerging Business Models\n",
    "- Detailed business model deconstruction\n",
    "- Scalability matrix\n",
    "- Financial modeling across different scenarios\n",
    "- Risk-adjusted potential analysis\n",
    "- Comparative global business model variations\n",
    "\n",
    "5. Investment Criteria Development\n",
    "**Qualitative Dimensions:**\n",
    "- Team expertise deep-dive\n",
    "- Network effect potential\n",
    "- Strategic partnership ecosystem\n",
    "\n",
    "Quantitative Metrics:\n",
    "- Standardized performance indicators\n",
    "- Risk-adjusted return projections\n",
    "- Comparative benchmark analysis\n",
    "- Funding efficiency ratio\n",
    "\n",
    "### 6. High-Potential Sub-Sector Identification\n",
    "- Multi-dimensional growth potential assessment\n",
    "- Include:\n",
    "  * Market size\n",
    "  * Growth trajectory\n",
    "  * Technological readiness\n",
    "  * Regulatory environment\n",
    "  * Global competitiveness index\n",
    "\n",
    "### 7. Comprehensive Risk Analysis\n",
    "- Holistic risk framework covering:\n",
    "  * Technological risks\n",
    "  * Market adoption risks\n",
    "  * Regulatory risks\n",
    "  * Geopolitical risks\n",
    "- Scenario planning\n",
    "- Mitigation strategy development\n",
    "- Probabilistic risk assessment\n",
    "\n",
    "## Methodological Requirements\n",
    "- Mandatory use of:\n",
    "  * Peer-reviewed sources\n",
    "  * Government reports\n",
    "  * Industry expert consultations\n",
    "- Transparent methodology disclosure\n",
    "- Bias acknowledgment section\n",
    "\n",
    "## Reporting Standards\n",
    "- Clear, structured presentation\n",
    "- Visual data representations\n",
    "- Explicit uncertainty indicators\n",
    "- Comparative global context\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dfd8361",
   "metadata": {
    "height": 1203
   },
   "outputs": [],
   "source": [
    "COMPANY_RESEARCH_PROMPT = \"\"\"\n",
    "You are an expert deal sourcer for venture capital. \n",
    "Using the provided research context and the comprehensive industry thesis, identify and analyze potential investment targets. \n",
    "For each company, your analysis should include:\n",
    "# Advanced Company Research and Evaluation Protocol\n",
    "\n",
    "## Comprehensive Company Analysis Framework\n",
    "\n",
    "### 1. Company Overview - Multidimensional Assessment\n",
    "- Global context mapping\n",
    "- Technological positioning\n",
    "- Socio-economic impact potential\n",
    "- Comparative ecosystem analysis\n",
    "\n",
    "### 2. Funding and Financial Forensics\n",
    "- Detailed funding archaeology\n",
    "  * Investor reputation analysis\n",
    "  * Capital efficiency metrics\n",
    "  * Funding source diversification\n",
    "- Transparent funding gap identification\n",
    "- Non-dilutive funding potential assessment\n",
    "\n",
    "### 3. Technological Innovation Validation\n",
    "- Rigorous innovation assessment protocol:\n",
    "  * Independent technical review\n",
    "  * Comparative technological benchmark\n",
    "  * Scalability simulation\n",
    "  * Potential integration challenges\n",
    "- Technology Readiness Level (TRL) mapping\n",
    "- Potential failure mode analysis\n",
    "\n",
    "### 4. Investment Thesis Alignment\n",
    "**Quantitative Alignment Metrics:**\n",
    "- Market trend correlation index\n",
    "- Technological disruption potential\n",
    "- Scalability probability matrix\n",
    "\n",
    "**Qualitative Alignment Factors:**\n",
    "- Strategic adaptability\n",
    "- Team's innovation historical track record\n",
    "- Global market responsiveness\n",
    "\n",
    "### 5. Risk and Challenge Comprehensive Mapping\n",
    "- Multidimensional risk assessment:\n",
    "  * Technological risks\n",
    "  * Market adoption risks\n",
    "  * Regulatory landscape challenges\n",
    "  * Competitive ecosystem threats\n",
    "- Scenario planning\n",
    "- Mitigation strategy development\n",
    "\n",
    "### 6. Comparative Analysis Requirements\n",
    "- Mandatory cross-company and cross-geographical comparisons\n",
    "- Standardized evaluation metrics\n",
    "- Explicit bias acknowledgment\n",
    "\n",
    "## Reporting Methodology\n",
    "- Transparent data sourcing\n",
    "- Visual comparative frameworks\n",
    "- Explicit uncertainty indicators\n",
    "- Probabilistic potential projections\n",
    "\n",
    "## Mandatory Documentation\n",
    "- Comprehensive source references\n",
    "- Methodology disclosure\n",
    "- Expert consultation summaries\n",
    "\n",
    "Industry Thesis:\n",
    "{industry_thesis}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9b1d363",
   "metadata": {
    "height": 1526
   },
   "outputs": [],
   "source": [
    "DUE_DILIGENCE_PROMPT = \"\"\"\n",
    "Conduct a comprehensive due diligence analysis on the following startup. \n",
    "Your report should include detailed assessments:\n",
    "# Comprehensive Startup Due Diligence Protocol\n",
    "\n",
    "## 1. Business Model Forensic Analysis\n",
    "- Value Proposition Deconstruction\n",
    "  * Market need validation\n",
    "  * Comparative competitive positioning\n",
    "  * Revenue model resilience assessment\n",
    "- Customer Acquisition Strategy Evaluation\n",
    "  * Acquisition cost metrics\n",
    "  * Channel effectiveness\n",
    "  * Conversion probability analysis\n",
    "\n",
    "## 2. Market Potential Comprehensive Mapping\n",
    "- Total Addressable Market (TAM) Multi-Dimensional Assessment\n",
    "  * Global market segmentation\n",
    "  * Regional variation analysis\n",
    "  * Potential market expansion scenarios\n",
    "- Serviceable Available Market (SAM) Detailed Mapping\n",
    "  * Competitive landscape dynamics\n",
    "  * Market entry barriers\n",
    "  * Technological adoption probability\n",
    "\n",
    "## 3. Competitive Landscape Deep Dive\n",
    "- Competitive Positioning Matrix\n",
    "  * Technology comparative analysis\n",
    "  * Market share potential\n",
    "  * Competitive moat evaluation\n",
    "- Advanced SWOT Analysis\n",
    "  * Probabilistic scenario modeling\n",
    "  * Competitive threat identification\n",
    "  * Strategic adaptation potential\n",
    "\n",
    "## 4. Team Capability Forensic Review\n",
    "- Management Team Comprehensive Assessment\n",
    "  * Historical performance tracking\n",
    "  * Innovation capability index\n",
    "  * Network effect potential\n",
    "- Capability Gap Identification\n",
    "  * Strategic hiring recommendations\n",
    "  * Advisory board optimization\n",
    "\n",
    "## 5. Financial Health Comprehensive Analysis\n",
    "- Funding Ecosystem Mapping\n",
    "  * Investor reputation analysis\n",
    "  * Funding source diversification\n",
    "  * Capital efficiency metrics\n",
    "- Financial Stability Projection\n",
    "  * Burn rate analysis\n",
    "  * Runway scenario modeling\n",
    "  * Non-dilutive funding potential\n",
    "\n",
    "## 6. Technical and Operational Risk Mapping\n",
    "- Technology Risk Assessment\n",
    "  * Failure mode analysis\n",
    "  * Integration challenge evaluation\n",
    "  * Scalability simulation\n",
    "- Operational Risk Comprehensive Review\n",
    "  * Regulatory compliance probability\n",
    "  * Supply chain vulnerability analysis\n",
    "  * Technological adaptability potential\n",
    "\n",
    "## 7. Strategic Exit Pathway Analysis\n",
    "- Potential Exit Scenario Modeling\n",
    "  * Acquisition probability matrix\n",
    "  * IPO readiness assessment\n",
    "  * Comparative market liquidity analysis\n",
    "- Market Trend Contextual Evaluation\n",
    "\n",
    "## 8. Holistic Risk Assessment Framework\n",
    "- Integrated Risk Scoring\n",
    "  * Quantitative risk metrics\n",
    "  * Qualitative risk factors\n",
    "  * Probabilistic potential projection\n",
    "- Mitigation Strategy Development\n",
    "  * Risk prioritization\n",
    "  * Adaptive strategy recommendations\n",
    "\n",
    "## Reporting Methodology\n",
    "- Transparent data sourcing\n",
    "- Explicit uncertainty indicators\n",
    "- Comprehensive source documentation\n",
    "- Bias acknowledgment\n",
    "\n",
    "Company Details:\n",
    "{company_details}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0939dbb",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "class DealSourcingState(TypedDict):\n",
    "    industry: str\n",
    "    investment_thesis: str\n",
    "    initial_companies: List[dict]\n",
    "    researched_companies: List[dict]\n",
    "    due_diligence_notes: List[dict]\n",
    "    top_prospects: List[dict]\n",
    "    max_iterations: int\n",
    "    current_iteration: int\n",
    "    report_path: Optional[str]\n",
    "\n",
    "class CompanyInfo(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    funding_stage: str\n",
    "    total_funding: str\n",
    "    key_founders: List[str]\n",
    "    competitive_advantage: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef52ece",
   "metadata": {
    "height": 30
   },
   "source": [
    "##Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48218352",
   "metadata": {
    "height": 2206
   },
   "outputs": [],
   "source": [
    "def generate_industry_thesis(state: DealSourcingState):\n",
    "    \"\"\"Generate investment thesis for the specified industry\"\"\"\n",
    "    console.print(f\"[bold blue]Generating Thesis for {state['industry']} Industry[/bold blue]\")\n",
    "    try:\n",
    "        messages = [\n",
    "            SystemMessage(content=INDUSTRY_THESIS_PROMPT),\n",
    "            HumanMessage(content=state['industry'])\n",
    "        ]\n",
    "        \n",
    "        # Add more detailed logging\n",
    "        print(f\"🔍 Generating thesis for: {state['industry']}\")\n",
    "        print(f\"📋 System Prompt Length: {len(INDUSTRY_THESIS_PROMPT)} characters\")\n",
    "        \n",
    "        response = model.invoke(messages)\n",
    "        \n",
    "        print(f\"✅ Thesis Generated: {len(response.content)} characters\")\n",
    "        \n",
    "        console.print(Panel(\n",
    "            Text(response.content, style=\"bold white\"),\n",
    "            title=f\"[bold green]Investment Thesis: {state['industry']}\",\n",
    "            border_style=\"bold blue\"\n",
    "        ))\n",
    "        \n",
    "        return {\"investment_thesis\": response.content}\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Error in thesis generation: {e}[/red]\")\n",
    "        print(f\"❌ Thesis Generation Failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return {\"investment_thesis\": \"Failed to generate thesis\"}\n",
    "\n",
    "def research_companies(state: DealSourcingState):\n",
    "    \"\"\"Search and identify potential investment targets\"\"\"\n",
    "    console.print(\"[bold blue]Researching Companies[/bold blue]\")\n",
    "    search_queries = [\n",
    "        f\"Top emerging startups in {state['industry']} with recent funding\",\n",
    "        f\"Innovative companies disrupting {state['industry']} sector\",\n",
    "        f\"Best funded startups in {state['industry']} this year\"\n",
    "    ]\n",
    "    \n",
    "    companies = []\n",
    "    \n",
    "    for query in search_queries:\n",
    "        console.print(f\"\\n[bold blue]Searching: {query}[/bold blue]\")\n",
    "        \n",
    "        try:\n",
    "            print(f\"🔎 Executing Tavily search: {query}\")\n",
    "            search_results = tavily.search(query=query, max_results=3)\n",
    "            \n",
    "            print(f\"📊 Search Results: {len(search_results['results'])} items\")\n",
    "            \n",
    "            for result in search_results['results']:\n",
    "                try:\n",
    "                    print(f\"📝 Processing result: {result['title']}\")\n",
    "                    company_details = model.with_structured_output(CompanyInfo).invoke([\n",
    "                        SystemMessage(content=\"Extract structured company information from the text.\"),\n",
    "                        HumanMessage(content=result['content'])\n",
    "                    ])\n",
    "                    companies.append(company_details.dict())\n",
    "                    print(f\"✅ Company processed: {company_details.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error processing company: {e}\")\n",
    "                    traceback.print_exc()\n",
    "        \n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]Search error: {e}[/red]\")\n",
    "            print(f\"❌ Tavily Search Failed: {e}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    console.print(f\"[green]Found {len(companies)} companies[/green]\")\n",
    "    print(f\"📋 Companies Found: {len(companies)}\")\n",
    "    return {\"initial_companies\": companies}\n",
    "\n",
    "def run_deal_sourcing(industry, max_iterations=2):\n",
    "    \"\"\"Run the entire deal sourcing workflow with comprehensive logging\"\"\"\n",
    "    console.print(f\"[bold green]Starting Deal Sourcing for {industry} Industry[/bold green]\")\n",
    "    \n",
    "    thread = {\"configurable\": {\"thread_id\": \"deal_sourcing\"}}\n",
    "    initial_state = {\n",
    "        \"industry\": industry,\n",
    "        \"max_iterations\": max_iterations,\n",
    "        \"current_iteration\": 0,\n",
    "        \"initial_companies\": [],\n",
    "        \"researched_companies\": [],\n",
    "        \"due_diligence_notes\": [],\n",
    "        \"top_prospects\": [],\n",
    "        \"investment_thesis\": \"\"\n",
    "    }\n",
    "    \n",
    "    final_state = None\n",
    "    try:\n",
    "        print(f\"🚀 Workflow Initialization for {industry}\")\n",
    "        \n",
    "        # Direct step-by-step execution\n",
    "        print(\"🔍 Step 1: Generate Industry Thesis\")\n",
    "        thesis_result = generate_industry_thesis(initial_state)\n",
    "        initial_state.update(thesis_result)\n",
    "        \n",
    "        print(\"🔎 Step 2: Research Companies\")\n",
    "        research_result = research_companies(initial_state)\n",
    "        initial_state.update(research_result)\n",
    "        \n",
    "        print(\"📊 Step 3: Analyze Companies\")\n",
    "        analyze_result = analyze_companies(initial_state)\n",
    "        initial_state.update(analyze_result)\n",
    "        \n",
    "        print(\"🔬 Step 4: Due Diligence\")\n",
    "        diligence_result = due_diligence(initial_state)\n",
    "        initial_state.update(diligence_result)\n",
    "        \n",
    "        print(\"🏆 Step 5: Select Top Prospects\")\n",
    "        prospects_result = select_top_prospects(initial_state)\n",
    "        initial_state.update(prospects_result)\n",
    "        \n",
    "        final_state = initial_state\n",
    "        \n",
    "        print(\"📄 Workflow Completed Successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Workflow Execution Error: {e}[/red]\")\n",
    "        print(f\"❌ Workflow Failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    if final_state:\n",
    "        print(\"💾 Saving Results to Markdown\")\n",
    "        return save_results_to_markdown(final_state)\n",
    "    else:\n",
    "        console.print(\"[red]No final state generated[/red]\")\n",
    "        return None\n",
    "\n",
    "#######################\n",
    "def analyze_companies(state: DealSourcingState):\n",
    "    \"\"\"Conduct deeper research on initial companies\"\"\"\n",
    "    console.print(\"[bold blue]Analyzing Companies[/bold blue]\")\n",
    "    researched_companies = []\n",
    "    \n",
    "    for company in state['initial_companies']:\n",
    "        try:\n",
    "            research_context = \"\\n\".join([\n",
    "                f\"Previous research on {state['industry']}\",\n",
    "                state['investment_thesis']\n",
    "            ])\n",
    "            \n",
    "            messages = [\n",
    "                SystemMessage(content=COMPANY_RESEARCH_PROMPT.format(\n",
    "                    research_context=research_context,\n",
    "                    industry_thesis=state['investment_thesis']\n",
    "                )),\n",
    "                HumanMessage(content=str(company))\n",
    "            ]\n",
    "            \n",
    "            response = model.invoke(messages)\n",
    "            researched_companies.append({\n",
    "                \"company\": company,\n",
    "                \"detailed_research\": response.content\n",
    "            })\n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]Error analyzing company {company.get('name', 'Unknown')}: {e}[/red]\")\n",
    "    \n",
    "    console.print(f\"[green]Completed research for {len(researched_companies)} companies[/green]\")\n",
    "    return {\"researched_companies\": researched_companies}\n",
    "\n",
    "def due_diligence(state: DealSourcingState):\n",
    "    \"\"\"Perform due diligence on most promising companies\"\"\"\n",
    "    console.print(\"[bold blue]Conducting Due Diligence[/bold blue]\")\n",
    "    due_diligence_results = []\n",
    "    \n",
    "    for research_item in state['researched_companies'][:3]:  # Top 3 companies\n",
    "        try:\n",
    "            messages = [\n",
    "                SystemMessage(content=DUE_DILIGENCE_PROMPT),\n",
    "                HumanMessage(content=str(research_item))\n",
    "            ]\n",
    "            \n",
    "            response = model.invoke(messages)\n",
    "            due_diligence_results.append({\n",
    "                \"company\": research_item['company'],\n",
    "                \"due_diligence_notes\": response.content\n",
    "            })\n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]Error in due diligence for {research_item['company'].get('name', 'Unknown')}: {e}[/red]\")\n",
    "    \n",
    "    console.print(f\"[green]Completed due diligence for {len(due_diligence_results)} companies[/green]\")\n",
    "    return {\n",
    "        \"due_diligence_notes\": due_diligence_results,\n",
    "        \"current_iteration\": state.get(\"current_iteration\", 0) + 1\n",
    "    }\n",
    "\n",
    "def select_top_prospects(state: DealSourcingState):\n",
    "    \"\"\"Select top investment prospects\"\"\"\n",
    "    console.print(\"[bold blue]Selecting Top Prospects[/bold blue]\")\n",
    "    try:\n",
    "        top_prospects = sorted(\n",
    "            state['due_diligence_notes'], \n",
    "            key=lambda x: len(x['due_diligence_notes']), \n",
    "            reverse=True\n",
    "        )[:2]\n",
    "        \n",
    "        console.print(f\"[green]Selected {len(top_prospects)} top prospects[/green]\")\n",
    "        return {\"top_prospects\": top_prospects}\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Error selecting top prospects: {e}[/red]\")\n",
    "        return {\"top_prospects\": []}\n",
    "\n",
    "def should_continue(state):\n",
    "    \"\"\"Determine whether to continue iterating\"\"\"\n",
    "    console.print(f\"[yellow]Current Iteration: {state['current_iteration']} / {state['max_iterations']}[/yellow]\")\n",
    "    if state[\"current_iteration\"] >= state[\"max_iterations\"]:\n",
    "        return END\n",
    "    return \"analyze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51416122",
   "metadata": {
    "height": 1067
   },
   "outputs": [],
   "source": [
    "def save_results_to_markdown(state: Dict[str, Any], filename: str = None):\n",
    "    \"\"\"Save workflow results to a comprehensive markdown document\"\"\"\n",
    "    console.print(\"[bold blue]Saving Results to Markdown[/bold blue]\")\n",
    "    try:\n",
    "        industry = state.get('industry', 'Unspecified')\n",
    "        \n",
    "        if not filename:\n",
    "            filename = f\"{industry.lower().replace(' ', '_')}_deal_sourcing_report.md\"\n",
    "        \n",
    "        # Prepare markdown content with structured sections\n",
    "        md_content = f\"# Deal Sourcing Report: {industry} Industry\\n\\n\"\n",
    "        \n",
    "        # Investment Thesis Section\n",
    "        md_content += \"## Investment Thesis\\n\\n\"\n",
    "        md_content += f\"{state.get('investment_thesis', 'No detailed thesis generated.')}\\n\\n\"\n",
    "        \n",
    "        # Initial Companies Section\n",
    "        md_content += \"## Initial Companies Identified\\n\\n\"\n",
    "        for company in state.get('initial_companies', []):\n",
    "            md_content += f\"### {company.get('name', 'Unnamed Company')}\\n\"\n",
    "            md_content += f\"- **Description**: {company.get('description', 'No description')}\\n\"\n",
    "            md_content += f\"- **Funding Stage**: {company.get('funding_stage', 'Unknown')}\\n\"\n",
    "            md_content += f\"- **Total Funding**: {company.get('total_funding', 'Not disclosed')}\\n\\n\"\n",
    "        \n",
    "        # Researched Companies Section\n",
    "        md_content += \"## Detailed Company Research\\n\\n\"\n",
    "        for research_item in state.get('researched_companies', []):\n",
    "            company = research_item.get('company', {})\n",
    "            md_content += f\"### {company.get('name', 'Unnamed Company')}\\n\"\n",
    "            md_content += f\"{research_item.get('detailed_research', 'No research details')}\\n\\n\"\n",
    "        \n",
    "        # Due Diligence Section\n",
    "        md_content += \"## Due Diligence Findings\\n\\n\"\n",
    "        for diligence_item in state.get('due_diligence_notes', []):\n",
    "            company = diligence_item.get('company', {})\n",
    "            md_content += f\"### {company.get('name', 'Unnamed Company')}\\n\"\n",
    "            md_content += f\"{diligence_item.get('due_diligence_notes', 'No due diligence details')}\\n\\n\"\n",
    "        \n",
    "        # Top Prospects Section\n",
    "        md_content += \"## Top Investment Prospects\\n\\n\"\n",
    "        for prospect in state.get('top_prospects', []):\n",
    "            company = prospect.get('company', {})\n",
    "            md_content += f\"### {company.get('name', 'Unnamed Company')}\\n\"\n",
    "            md_content += f\"**Potential Fit**: High\\n\\n\"\n",
    "        \n",
    "        os.makedirs('reports', exist_ok=True)\n",
    "        filepath = os.path.join('reports', filename)\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(md_content)\n",
    "        \n",
    "        console.print(Panel(\n",
    "            Text(f\"Report saved to {filepath}\", style=\"bold green\"),\n",
    "            title=\"[bold blue]Deal Sourcing Report\",\n",
    "            border_style=\"green\"\n",
    "        ))\n",
    "        \n",
    "        return {\"report_path\": filepath}\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Error saving markdown: {e}[/red]\")\n",
    "        console.print(traceback.format_exc())\n",
    "        return {\"report_path\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6136758f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#buildingGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "683d31fc",
   "metadata": {
    "height": 370
   },
   "outputs": [],
   "source": [
    "# Build the workflow graph\n",
    "builder = StateGraph(DealSourcingState)\n",
    "builder.add_node(\"thesis\", generate_industry_thesis)\n",
    "builder.add_node(\"research\", research_companies)\n",
    "builder.add_node(\"analyze\", analyze_companies)\n",
    "builder.add_node(\"due_diligence\", due_diligence)\n",
    "builder.add_node(\"select_prospects\", select_top_prospects)\n",
    "\n",
    "builder.set_entry_point(\"thesis\")\n",
    "builder.add_edge(\"thesis\", \"research\")\n",
    "builder.add_edge(\"research\", \"analyze\")\n",
    "builder.add_edge(\"analyze\", \"due_diligence\")\n",
    "builder.add_edge(\"due_diligence\", \"select_prospects\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"select_prospects\", \n",
    "    should_continue, \n",
    "    {END: END, \"analyze\": \"analyze\"}\n",
    ")\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042a524",
   "metadata": {
    "height": 30
   },
   "source": [
    "#Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2e2253c",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Starting Deal Sourcing for Start ups in Energy transmission Industry</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mStarting Deal Sourcing for Start ups in Energy transmission Industry\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Workflow Initialization for Start ups in Energy transmission\n",
      "🔍 Step 1: Generate Industry Thesis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Generating Thesis for Start ups in Energy transmission Industry</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mGenerating Thesis for Start ups in Energy transmission Industry\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Generating thesis for: Start ups in Energy transmission\n",
      "📋 System Prompt Length: 2909 characters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error in thesis generation: Error code: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">429</span><span style=\"color: #800000; text-decoration-color: #800000\"> - </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">{</span><span style=\"color: #800000; text-decoration-color: #800000\">'error'</span><span style=\"color: #800000; text-decoration-color: #800000\">: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">{</span><span style=\"color: #800000; text-decoration-color: #800000\">'message'</span><span style=\"color: #800000; text-decoration-color: #800000\">: </span><span style=\"color: #800000; text-decoration-color: #800000\">'exceeded quota for this month'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">}}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError in thesis generation: Error code: \u001b[0m\u001b[1;31m429\u001b[0m\u001b[31m - \u001b[0m\u001b[1;31m{\u001b[0m\u001b[31m'error'\u001b[0m\u001b[31m: \u001b[0m\u001b[1;31m{\u001b[0m\u001b[31m'message'\u001b[0m\u001b[31m: \u001b[0m\u001b[31m'exceeded quota for this month'\u001b[0m\u001b[1;31m}\u001b[0m\u001b[1;31m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Thesis Generation Failed: Error code: 429 - {'error': {'message': 'exceeded quota for this month'}}\n",
      "🔎 Step 2: Research Companies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_69/4232923428.py\", line 14, in generate_industry_thesis\n",
      "    response = model.invoke(messages)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'exceeded quota for this month'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Researching Companies</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mResearching Companies\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Searching: Top emerging startups in Start ups in Energy transmission with recent funding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mSearching: Top emerging startups in Start ups in Energy transmission with recent funding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Executing Tavily search: Top emerging startups in Start ups in Energy transmission with recent funding\n",
      "📊 Search Results: 3 items\n",
      "📝 Processing result: Top 16 Energy Transfer (transmission) startups (March 2025)\n",
      "❌ Error processing company: Error code: 429 - {'error': {'message': 'exceeded quota for this month'}}\n",
      "📝 Processing result: List of Recently Funded Energy Startups for 2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_69/4232923428.py\", line 54, in research_companies\n",
      "    company_details = model.with_structured_output(CompanyInfo).invoke([\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 2368, in invoke\n",
      "    input = step.invoke(\n",
      "            ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 4396, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'exceeded quota for this month'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error processing company: Error code: 429 - {'error': {'message': 'exceeded quota for this month'}}\n",
      "📝 Processing result: List of Funded Energy Startups For 2024 - Growth List\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_69/4232923428.py\", line 54, in research_companies\n",
      "    company_details = model.with_structured_output(CompanyInfo).invoke([\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 2368, in invoke\n",
      "    input = step.invoke(\n",
      "            ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 4396, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'exceeded quota for this month'}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/openai/_base_client.py:999\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 999\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/httpx/_models.py:761\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 761\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'http://jupyter-api-proxy.internal.dlai/rev-proxy/langchain_langgraph/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mrun_deal_sourcing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStart ups in Energy transmission\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 99\u001b[0m, in \u001b[0;36mrun_deal_sourcing\u001b[0;34m(industry, max_iterations)\u001b[0m\n\u001b[1;32m     96\u001b[0m initial_state\u001b[38;5;241m.\u001b[39mupdate(thesis_result)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔎 Step 2: Research Companies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m research_result \u001b[38;5;241m=\u001b[39m \u001b[43mresearch_companies\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m initial_state\u001b[38;5;241m.\u001b[39mupdate(research_result)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📊 Step 3: Analyze Companies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 54\u001b[0m, in \u001b[0;36mresearch_companies\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📝 Processing result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m     company_details \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCompanyInfo\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExtract structured company information from the text.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     companies\u001b[38;5;241m.\u001b[39mappend(company_details\u001b[38;5;241m.\u001b[39mdict())\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Company processed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompany_details\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/langchain_core/runnables/base.py:2368\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2367\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2368\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2374\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2375\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/langchain_core/runnables/base.py:4396\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   4391\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4392\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4393\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4394\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4395\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 4396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4400\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:170\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    167\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    169\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    180\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:599\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    593\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    598\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:456\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    455\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    457\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    458\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    460\u001b[0m ]\n\u001b[1;32m    461\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:446\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 446\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:671\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 671\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:522\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    521\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 522\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/openai/resources/chat/completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/openai/_base_client.py:1051\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1047\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1054\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1055\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1059\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_deal_sourcing(\"Start ups in Energy transmission\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
